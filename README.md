<img src="https://raw.githubusercontent.com/me-shweta/Design-Den/main/Reviews%20Scraping%20Image.png" align="center"/>

 <h2 align="center"><picture>
  <source srcset="https://fonts.gstatic.com/s/e/notoemoji/latest/1faa9/512.webp" type="image/webp">
  <img src="https://fonts.gstatic.com/s/e/notoemoji/latest/1faa9/512.gif" alt="ü™©" width="32" height="32">
</picture>IMDB Movie review Scrapping<picture>
  <source srcset="https://fonts.gstatic.com/s/e/notoemoji/latest/2699_fe0f/512.webp" type="image/webp">
  <img src="https://fonts.gstatic.com/s/e/notoemoji/latest/2699_fe0f/512.gif" alt="‚öô" width="32" height="32">
</picture></h2>
<blockquote align="center"><b>Scraping the movie review ‚úèÔ∏è using python programming languageüíª. </b> </blockquote>
<div align="center">
  
<!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section -->

[![All Contributors](https://img.shields.io/badge/all_contributors-1-orange.svg?style=flat-square)](#contributors-)
<a href="https://github.com/recodehive/awesome-github-profiles/stargazers"><img src="https://img.shields.io/github/stars/recodehive/awesome-github-profiles" alt="Stars Badge"/></a>
<a href="https://github.com/recodehive/awesome-github-profiles/network/members"><img src="https://img.shields.io/github/forks/recodehive/awesome-github-profiles" alt="Forks Badge"/></a>
<a href="https://github.com/recodehive/awesome-github-profiles/pulls"><img src="https://img.shields.io/github/issues-pr/recodehive/awesome-github-profiles" alt="Pull Requests Badge"/></a>
<a href="https://github.com/recodehive/awesome-github-profiles/issues"><img src="https://img.shields.io/github/issues/recodehive/awesome-github-profiles" alt="Issues Badge"/></a>
<a href="https://github.com/recodehive/awesome-github-profiles/graphs/contributors"><img alt="GitHub contributors" src="https://img.shields.io/github/contributors/recodehive/awesome-github-profiles?color=2b9348"></a>
<a href="https://github.com/recodehive/awesome-github-profiles/blob/master/LICENSE"><img src="https://img.shields.io/github/license/recodehive/awesome-github-profiles?color=2b9348" alt="License Badge"/></a>
[![](https://visitcount.itsvg.in/api?id=gssoc-postman&label=Profile%20Views&color=0&icon=5&pretty=true)](https://visitcount.itsvg.in)
<!-- ALL-CONTRIBUTORS-BADGE:END -->
üîçWelcome to the IMDb Movie Review Scraper project! üåü.
</div>

<br> This Python script is designed to scrape movie reviews from IMDb, to facilitate analysis and research. The IMDb Movie Review Scraping project aims to gather a new dataset by automatically extracting movie reviews from IMDb. This dataset will support various natural language processing tasks, including sentiment analysis and recommendation systems. Using web scraping techniques, such as Beautiful Soup, movie reviews are collected, preprocessed, and structured into a CSV format suitable for analysis, including Support Vector Machine classification. üìà

## <picture>
  <source srcset="https://fonts.gstatic.com/s/e/notoemoji/latest/2699_fe0f/512.webp" type="image/webp">
</picture><b style="font-size:3vw">Features</b>

**`Semi-supervised-sequence-learning-Project`** : replication process is done over here and for further analysis creation of new data is required.

1. Scraping Movie Reviews üïµÔ∏è‚Äç‚ôÇÔ∏è
- `Movie_review_imdb_scrapping.ipynb` - The script fetches user reviews from IMDb, providing access to a diverse range of opinions and feedback for different movies. It utilizes BeautifulSoup, a powerful Python library for web scraping, to extract data from IMDb's web pages efficiently and accurately. üé•üîé

2. Customizable Scraper üõ†Ô∏è
- `rename_files.ipynb` - Users can customize the scraper to target specific time periods, ratings, and other parameters, enabling focused data collection based on their requirements. This flexibility allows researchers, analysts, and enthusiasts to tailor the scraping process to their specific needs. <picture>
  <source srcset="https://fonts.gstatic.com/s/e/notoemoji/latest/1f3af/512.webp" type="image/webp">
  <img src="https://fonts.gstatic.com/s/e/notoemoji/latest/1f3af/512.gif" alt="üéØ" width="32" height="32">
</picture>

3. CSV Output üìÅ
- `convert_texts_to_csv.ipynb` - The scraped data is saved into a CSV file, allowing for easy import into data analysis software or further processing. The CSV format ensures compatibility with a wide range of tools and platforms, making it convenient to incorporate the scraped data into various workflows and projects. üíæüíº


<!--line-->
<img src="https://www.animatedimages.org/data/media/562/animated-line-image-0184.gif" width="1920" />



## This project is now OFFICIALLY accepted for

<div align="center">
  <img src="https://github.com/amiya-cyber/banner/blob/main/329829127-e79eb6de-81b1-4ffb-b6ed-f018bb977e88.png" alt="GSSoC 2024 Extd" width="60%">
</div>

<div align="center">
  <img src="https://github.com/amiya-cyber/banner/blob/main/hacktober.png" alt="Hacktober fest 2024" width="60%">
</div>

<!--line-->
<img src="https://www.animatedimages.org/data/media/562/animated-line-image-0184.gif" width="1920" />



## Getting Started

**Dependencies**

Make sure you have the following dependencies installed:

* Python 3.x
* BeautifulSoup (Install using ```pip install beautifulsoup4```
* Pandas (Install using ```pip install pandas```

**Installation**

1. **Fork the `Semi-supervised-sequence-learning-Project/` repository** 
   Link to [`Semi-supervised-sequence-learning-Project'](https://github.com/sanjay-kv/Semi-supervised-sequence-learning-Project) 
   Follow these instructions on [how to fork a repository](https://help.github.com/en/articles/fork-a-repo)

2. **Clone the Repository to your local machine**
   - using SSH:
     ```
     git clone git@github.com:your-username/Semi-supervised-sequence-learning-Project.git
     ```
   - Or using HTTPS:
     ```
     git clone https://github.com/your-username/Semi-supervised-sequence-learning-Project.git
     ```
3. **Navigate to the project directory.**
```
cd Semi-supervised-sequence-learning-Project
``` 
## Troubleshooting

### Dependency Installation Issues
If you encounter issues while installing dependencies such as `BeautifulSoup` or `Pandas`, try the following:
- Ensure you're using the correct version of Python (check the project's requirements).
- Use `pip` to install the necessary libraries:
    ```bash
    pip install beautifulsoup4 pandas
    ```
- If you encounter permission errors, try adding `--user` to the installation command:
    ```bash
    pip install --user beautifulsoup4 pandas
    ```
- For missing or outdated dependencies, create a virtual environment and install the required packages:
    ```bash
    python -m venv env
    source env/bin/activate  # On Windows use `env\Scripts\activate`
    pip install -r requirements.txt
    ```

### Scraping Errors
If the script fails to fetch reviews or if there are changes to the website:
- **Inspect the Website**: The structure of the HTML may have changed. Use browser developer tools (F12) to inspect the elements you're scraping.
- **Update Selectors**: Modify the CSS selectors or XPath in the script to match the current structure of the webpage.
- **Check for Blocked Requests**: Websites may block scraping requests. Use headers in your requests to mimic a regular browser:
    ```python
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"
    }
    response = requests.get(url, headers=headers)
    ```

### CSV Format Issues
If you're facing problems with the CSV file format:
- **Ensure Proper Formatting**: Verify that the CSV file is correctly formatted. Each field should be separated by commas, and text fields should be enclosed in quotes if they contain commas.
- **Check Encoding**: Ensure the file is saved with UTF-8 encoding to prevent issues with special characters.
- **Verify Column Names**: If your script requires specific column names, ensure they match exactly.
   

## Usage

**Starting the Streamlit app**

1. Navigate to the Web_app directory

```
cd Web_app
```

2. Install requirements with pip

```
pip install -r requirements.txt
```
3. Run the Streamlit app

```
streamlit run streamlit_app.py
```

**Uploading the CSV file**

When prompted by the app, upload a CSV (comma separated value) file containing the reviews.

**Demo Link**

Streamlit app link: https://scrape-review-analysis.streamlit.app

## Contribution
<picture>
  <source srcset="https://fonts.gstatic.com/s/e/notoemoji/latest/1f389/512.webp" type="image/webp">
  <img src="https://fonts.gstatic.com/s/e/notoemoji/latest/1f389/512.gif" alt="üéâ" width="32" height="32">
</picture>Contributions are welcome! If you have any suggestions for improvements or new features, please feel free to submit a pull request. Your contributions help make this project better for everyone. <picture>
  <source srcset="https://fonts.gstatic.com/s/e/notoemoji/latest/1f680/512.webp" type="image/webp">
  <img src="https://fonts.gstatic.com/s/e/notoemoji/latest/1f680/512.gif" alt="üöÄ" width="32" height="32">
</picture>
<div align="Left">
<h2><font size="6">
<picture>
  <source srcset="https://fonts.gstatic.com/s/e/notoemoji/latest/1f525/512.webp" type="image/webp">
  <img src="https://fonts.gstatic.com/s/e/notoemoji/latest/1f525/512.gif" alt="üî•" width="32" height="32">
</picture>Contribution</font></h2>
</div>
<h3>This project thanks all the contributors for having your valuable contribution to our project</h3>
<br>

<center>
<a href="https://github.com/Recode-Hive/Scrape-ML/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=Recode-Hive/Scrape-ML" />
</a>
</center>
<br>

## Final Dataset

üî¨Here is the Link to **Final Dataset:** [Drive Link](https://drive.google.com/file/d/1sTNAeuy-99Hao0V5AOVznLXyDJC2zuFn/view?usp=sharing) containing the scraped IMDb movie reviews. This dataset can be used for analysis, research, or any other purposes you require. üì¶
## Support

<picture>
  <source srcset="https://fonts.gstatic.com/s/e/notoemoji/latest/2728/512.webp" type="image/webp">
  <img src="https://fonts.gstatic.com/s/e/notoemoji/latest/2728/512.gif" alt="‚ú®" width="20" height="20">
</picture>For any issues regarding the scraper, feel free to open an issue on GitHub. We'll be happy to assist you with any problems or inquiries you may have. üõ†Ô∏è

<p align="right"><a href="#top">Back to top</a></p>
*

## üåê Connect with Me

<div align="center">
    <a href="https://x.com/sanjay_k_v">
        <img src="https://img.shields.io/badge/Twitter-1DA1F2?style=flat-square&logo=twitter&logoColor=white" alt="Twitter" width="100" height="30"/>
    </a>
    <a href="mailto:sanjay@recodehive.com">
        <img src="https://img.shields.io/badge/Email-D14836?style=flat-square&logo=gmail&logoColor=white" alt="Email" width="100" height="30"/>
    </a>
    <a href="https://github.com/recodehive/Scrape-ML">
        <img src="https://img.shields.io/badge/GitHub-181717?style=flat-square&logo=github&logoColor=white" alt="GitHub" width="100" height="30"/>
    </a>
</div>

---

Thank you for visiting! Feel free to reach out through any of the links above.
